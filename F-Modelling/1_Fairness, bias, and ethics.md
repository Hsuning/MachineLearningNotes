# 1_Fairness, bias, and ethics
```toc
```

**Important to ensure that the system is reasonably fair, free from bias, using an ethic approach**

## Bias
- Hiring tool that discriminates against women
- Face recognition system matching dark skinned individuals to criminal mugshots
- Biased bank loan approvals
- Toxic effect of reinforcing negative stereotypes

## Adverse Use Cases
- Deepfakes of former u.s. president
- Spreading toxic/incendiary speech through optimizing for engagement
- Generating fake content for commercial or political purposes
- Using ML to build harmful products, commit fraud etc
- Negative impact on the society

## Guidelines
- Get a diverse team (gender, ethnicity, culture, etc) to brainstorm things that might go wrong, with emphasis on possible harm to vulnerable groups
- Carry out literature search on standards/guidelines for your industry
- Audit systems against possible harm prior to deployment
- Develop mitigation plan (like a rollback to the earlier system), and after deployment, monitor for possible harm
